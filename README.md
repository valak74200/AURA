# ğŸ¯ AURA - Assistant de Coaching de PrÃ©sentation AlimentÃ© par l'IA

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue.svg)](https://postgresql.org)
[![Gemini AI](https://img.shields.io/badge/Gemini-AI-orange.svg)](https://ai.google.dev)
[![WebSocket](https://img.shields.io/badge/WebSocket-Real--time-red.svg)](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API)

**AURA** est une plateforme avancÃ©e de coaching vocal et de prÃ©sentation qui combine l'intelligence artificielle moderne avec des techniques d'analyse audio en temps rÃ©el pour offrir une expÃ©rience de formation personnalisÃ©e et efficace.

## ğŸŒŸ FonctionnalitÃ©s Principales

### ğŸ¤ **Analyse Audio AvancÃ©e**
- **Traitement temps rÃ©el** de chunks audio (100ms Ã  16kHz)
- **MÃ©triques vocales complÃ¨tes** : volume, clartÃ©, rythme, tonalitÃ©, pauses
- **Support multi-format** : WAV, MP3, M4A, OGG (jusqu'Ã  10MB)
- **DÃ©tection d'activitÃ© vocale** et analyse de qualitÃ© automatique

### ğŸ¤– **IA de Coaching Intelligente**
- **Feedback personnalisÃ©** gÃ©nÃ©rÃ© par Google Gemini AI
- **Suggestions temps rÃ©el** pendant la prÃ©sentation
- **Analyse contextuelle** basÃ©e sur le type de session
- **Conseils actionnables** en franÃ§ais avec encouragement adaptatif

### ğŸ“Š **Analytics et MÃ©triques**
- **Suivi de progression** avec tendances temporelles
- **Comparaisons benchmark** et objectifs personnels
- **DÃ©tection de jalons** d'amÃ©lioration
- **Rapports dÃ©taillÃ©s** avec visualisation des progrÃ¨s

### âš¡ **Communication Temps RÃ©el**
- **WebSocket streaming** pour feedback instantanÃ©
- **Pipeline de traitement** modulaire et extensible
- **Commandes de contrÃ´le** : start/stop, pause, configuration
- **Notifications de performance** et alertes live

## ğŸ—ï¸ Architecture du SystÃ¨me

```mermaid
graph TB
    subgraph "Client Layer"
        A[React Frontend] 
        B[Mobile App]
        C[Audio Input]
    end
    
    subgraph "API Gateway"
        D[FastAPI Server]
        E[WebSocket Handler]
        F[Authentication]
    end
    
    subgraph "Core Services"
        G[Audio Service]
        H[Storage Service]
        I[Gemini AI Service]
    end
    
    subgraph "Processing Pipeline"
        J[Analysis Processor]
        K[Feedback Processor]
        L[Metrics Processor]
        M[AURA Pipeline]
    end
    
    subgraph "Data Layer"
        N[PostgreSQL]
        O[Session Storage]
        P[Audio Buffer]
    end
    
    A --> D
    B --> D
    C --> E
    D --> F
    E --> G
    F --> H
    G --> J
    J --> K
    K --> L
    M --> I
    J --> M
    K --> M
    L --> M
    H --> N
    G --> P
    I --> O
```

## ğŸ”„ Pipeline de Traitement Audio

```mermaid
sequenceDiagram
    participant C as Client
    participant WS as WebSocket
    participant AP as AURA Pipeline
    participant AS as Audio Service
    participant FP as Feedback Processor
    participant AI as Gemini AI
    
    C->>WS: Audio Chunk (100ms)
    WS->>AP: ProcessorPart
    AP->>AS: Audio Analysis
    AS-->>AP: Voice Metrics
    AP->>FP: Analysis Results
    FP->>AI: Generate Feedback
    AI-->>FP: AI Suggestions
    FP-->>AP: Coaching Data
    AP->>WS: Real-time Results
    WS->>C: Live Feedback
    
    Note over AP: Parallel Processing
    Note over AI: French Coaching
    Note over C: Instant UI Update
```

## ğŸš€ Installation et Configuration

### PrÃ©requis
- Python 3.11+
- PostgreSQL 15+
- Google Cloud Account (pour Gemini AI)

### 1. Cloner le Projet
```bash
git clone https://github.com/valak74200/AURA.git
cd AURA/backend
```

### 2. Environnement Virtuel
```bash
python -m venv venv311
source venv311/bin/activate  # Linux/Mac
# ou
venv311\Scripts\activate     # Windows
```

### 3. Installation des DÃ©pendances
```bash
pip install -r requirements.txt
```

### 4. Configuration Environnement
CrÃ©er un fichier `.env` :

```bash
# API Keys
GEMINI_API_KEY=votre_clÃ©_gemini_ici
GOOGLE_CLOUD_PROJECT=votre_projet_gcp

# Base de DonnÃ©es
DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/aura_db

# Configuration Serveur
DEBUG=false
LOG_LEVEL=INFO
SECRET_KEY=votre_clÃ©_secrÃ¨te_32_caractÃ¨res_minimum

# Audio Processing
MAX_AUDIO_FILE_SIZE=10485760  # 10MB
AUDIO_SAMPLE_RATE=16000
AUDIO_CHUNK_SIZE=1600         # 100ms Ã  16kHz

# ModÃ¨les IA
DEFAULT_GEMINI_MODEL=gemini-2.5-flash
GEMINI_PRO_MODEL=gemini-2.5-pro
```

### 5. Base de DonnÃ©es
```bash
# CrÃ©er la base de donnÃ©es
python setup_database.py

# DÃ©marrer le serveur
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## ğŸ“¡ API Endpoints

### ğŸ” Authentication
```http
POST /api/v1/auth/register    # Inscription utilisateur
POST /api/v1/auth/login       # Connexion
GET  /api/v1/user/profile     # Profil utilisateur
```

### ğŸ­ Session Management
```http
POST   /api/v1/sessions                    # CrÃ©er session
GET    /api/v1/sessions/{id}              # RÃ©cupÃ©rer session
PUT    /api/v1/sessions/{id}              # Mettre Ã  jour
DELETE /api/v1/sessions/{id}              # Supprimer
GET    /api/v1/sessions?user_id=...       # Lister avec filtres
```

### ğŸ¤ Audio Processing
```http
POST /api/v1/sessions/{id}/audio/upload   # Upload fichier audio
POST /api/v1/sessions/{id}/audio/analyze  # Analyse chunk temps rÃ©el
```

### ğŸ’¬ Feedback & Analytics
```http
GET  /api/v1/sessions/{id}/feedback           # RÃ©cupÃ©rer feedback
POST /api/v1/sessions/{id}/feedback/generate  # GÃ©nÃ©rer feedback custom
GET  /api/v1/sessions/{id}/analytics          # Analytics dÃ©taillÃ©es
```

### ğŸ”§ System
```http
GET /api/v1/health    # Health check
GET /api/v1/test      # Tests d'intÃ©gration
```

### âš¡ WebSocket Endpoints
```http
WS /ws/session/{session_id}    # Connexion temps rÃ©el
WS /ws/test                    # Endpoint de test
```

## ğŸ”Œ Utilisation WebSocket

### Connexion et Messages
```javascript
// Connexion
const ws = new WebSocket('ws://localhost:8000/ws/session/123')

// Envoyer chunk audio
ws.send(JSON.stringify({
  type: 'audio_chunk',
  audio_data: base64AudioData,
  sample_rate: 16000,
  timestamp: Date.now()
}))

// Messages reÃ§us
ws.onmessage = (event) => {
  const data = JSON.parse(event.data)
  switch(data.type) {
    case 'coaching_result':
      // RÃ©sultats d'analyse complÃ¨te
      break
    case 'realtime_feedback':
      // Suggestions instantanÃ©es
      break
    case 'milestone_achieved':
      // Jalons atteints
      break
  }
}
```

## ğŸ§ª Tests

### ExÃ©cuter tous les Tests
```bash
# Tests complets
pytest tests/ -v

# Tests spÃ©cifiques
pytest tests/test_api/test_sessions.py -v
pytest tests/test_services/ -v

# Avec couverture
pytest tests/ --cov=app --cov-report=html
```

### Structure des Tests
```
tests/
â”œâ”€â”€ conftest.py                 # Configuration pytest
â”œâ”€â”€ test_api/
â”‚   â”œâ”€â”€ test_auth.py           # Tests authentification
â”‚   â”œâ”€â”€ test_sessions.py       # Tests sessions (24 tests)
â”‚   â””â”€â”€ test_websocket.py      # Tests WebSocket
â”œâ”€â”€ test_services/
â”‚   â””â”€â”€ test_auth_service.py   # Tests services
â””â”€â”€ test_processors/           # Tests pipeline
```

## ğŸ“Š ModÃ¨les de DonnÃ©es

### Session
```python
{
  "id": "uuid",
  "user_id": "string",
  "title": "string", 
  "session_type": "practice|presentation|training",
  "language": "fr|en",
  "status": "active|completed|paused",
  "config": {
    "max_duration": 1800,
    "feedback_frequency": 5,
    "real_time_feedback": true,
    "ai_coaching": true
  },
  "created_at": "datetime",
  "started_at": "datetime",
  "ended_at": "datetime"
}
```

### Feedback IA
```python
{
  "session_id": "uuid",
  "feedback_items": [
    {
      "type": "volume|pace|clarity",
      "category": "technique|delivery|content",
      "severity": "info|warning|critical",
      "message": "Votre volume est appropriÃ©",
      "score": 0.8,
      "suggestions": ["Continuez ainsi"]
    }
  ],
  "generated_at": "datetime"
}
```

## ğŸ”§ Configuration AvancÃ©e

### Pipeline de Traitement
```python
# ConfigurÃ© dans AuraPipeline
pipeline_config = {
    "enable_parallel_processing": True,
    "chunk_timeout_seconds": 5.0,
    "error_retry_count": 2,
    "feedback_throttling": True,
    "metrics_calculation_interval": 3,
    "quality_threshold": 0.5
}
```

### ModÃ¨les Gemini
```python
# Configuration IA
DEFAULT_GEMINI_MODEL = "gemini-2.5-flash"      # Rapide
GEMINI_PRO_MODEL = "gemini-2.5-pro"            # QualitÃ© max
DEFAULT_THINKING_BUDGET = 1000                  # Tokens
```

## ğŸš€ DÃ©ploiement

### Docker (RecommandÃ©)
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Production
```bash
# Avec Gunicorn
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8000

# Avec variables d'environnement production
export ENVIRONMENT=production
export DEBUG=false
export LOG_LEVEL=WARNING
```

## ğŸ“ˆ Monitoring et Performance

### MÃ©triques Disponibles
- **Temps de traitement** par chunk audio
- **Taux de succÃ¨s** du pipeline
- **Utilisation des services** (Storage, Audio, Gemini)
- **Erreurs et exceptions** avec traces complÃ¨tes
- **Sessions actives** et statistiques d'usage

### Logs StructurÃ©s
```python
# Format JSON avec mÃ©tadonnÃ©es complÃ¨tes
{
  "timestamp": "2024-01-01T12:00:00Z",
  "level": "INFO",
  "logger": "aura.processors.pipeline",
  "message": "Pipeline processing completed",
  "session_id": "uuid",
  "chunk_number": 42,
  "processing_time_ms": 150.5
}
```

## ğŸ¤ Contribution

### Structure du Code
```
app/
â”œâ”€â”€ api/                 # Endpoints FastAPI
â”œâ”€â”€ config.py           # Configuration
â”œâ”€â”€ database.py         # Connexion DB
â””â”€â”€ main.py             # Application principale

models/                 # ModÃ¨les Pydantic
â”œâ”€â”€ session.py
â”œâ”€â”€ feedback.py
â”œâ”€â”€ analytics.py
â””â”€â”€ user.py

processors/             # Pipeline de traitement
â”œâ”€â”€ aura_pipeline.py    # Pipeline principal
â”œâ”€â”€ analysis_processor.py
â”œâ”€â”€ feedback_processor.py
â””â”€â”€ metrics_processor.py

services/               # Services mÃ©tier
â”œâ”€â”€ audio_service.py
â”œâ”€â”€ storage_service.py
â”œâ”€â”€ gemini_service.py
â””â”€â”€ auth_service.py

utils/                  # Utilitaires
â”œâ”€â”€ logging.py
â”œâ”€â”€ exceptions.py
â””â”€â”€ audio_utils.py
```

### Standards de Code
- **Type hints** obligatoires
- **Docstrings** pour toutes les fonctions publiques
- **Tests** pour chaque nouvelle fonctionnalitÃ©
- **Logging** structurÃ© avec contexte
- **Gestion d'erreurs** avec exceptions custom

## ğŸ“ Roadmap

### âœ… ComplÃ©tÃ©
- [x] Architecture FastAPI complÃ¨te
- [x] Pipeline audio temps rÃ©el
- [x] IntÃ©gration Gemini AI
- [x] WebSocket streaming
- [x] Tests complets (88 tests passants)
- [x] Analytics avancÃ©es
- [x] Documentation API

### ğŸ”„ En Cours
- [ ] Interface React + Vite.js
- [ ] Capture microphone temps rÃ©el
- [ ] Dashboard analytics visuel
- [ ] Mobile app

### ğŸš€ Futur
- [ ] Support multi-langues (EN, ES)
- [ ] IntÃ©gration vidÃ©o
- [ ] Analytics prÃ©dictives
- [ ] API publique avec rate limiting
- [ ] DÃ©ploiement cloud (AWS/GCP)

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ†˜ Support

- **Documentation API** : http://localhost:8000/docs (Swagger)
- **Issues** : [GitHub Issues](https://github.com/valak74200/AURA/issues)

---

<div align="center">
  <strong>ğŸ¯ AURA - Transformez vos prÃ©sentations avec l'IA</strong><br/>
  DÃ©veloppÃ© avec â¤ï¸ pour l'excellence oratoire
</div>
