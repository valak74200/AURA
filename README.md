# ğŸ¯ AURA - Assistant de Coaching de PrÃ©sentation AlimentÃ© par l'IA

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue.svg)](https://postgresql.org)
[![Gemini AI](https://img.shields.io/badge/Gemini-AI-orange.svg)](https://ai.google.dev)
[![ElevenLabs TTS](https://img.shields.io/badge/ElevenLabs-TTS-purple.svg)](https://api.elevenlabs.io)
[![WebSocket](https://img.shields.io/badge/WebSocket-Real--time-red.svg)](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API)

**AURA** est une plateforme avancÃ©e de coaching vocal et de prÃ©sentation qui combine l'intelligence artificielle moderne avec des techniques d'analyse audio en temps rÃ©el pour offrir une expÃ©rience de formation personnalisÃ©e et efficace.

## ğŸŒŸ FonctionnalitÃ©s Principales

### ğŸŒ **Support Multilingue AvancÃ©**
- **Langues supportÃ©es** : FranÃ§ais et Anglais avec adaptation culturelle complÃ¨te
- **Analyse audio adaptative** : seuils et mÃ©triques optimisÃ©s par langue
- **Coaching culturel** : style franÃ§ais (structure/Ã©lÃ©gance) vs anglais (engagement/storytelling)
- **Benchmarks spÃ©cifiques** : comparaisons de performance par langue
- **Interface localisÃ©e** : messages et feedback dans la langue de session

### ğŸ¤ **Analyse Audio AvancÃ©e**
- **Traitement temps rÃ©el** de chunks audio (100ms Ã  16kHz)
- **MÃ©triques vocales complÃ¨tes** : volume, clartÃ©, rythme, tonalitÃ©, pauses
- **Support multi-format** : WAV, MP3, M4A, OGG (jusqu'Ã  10MB)
- **DÃ©tection d'activitÃ© vocale** et analyse de qualitÃ© automatique
- **Adaptation linguistique** : paramÃ¨tres d'analyse optimisÃ©s par langue

### ğŸ¤– **IA de Coaching Intelligente**
- **Feedback personnalisÃ©** gÃ©nÃ©rÃ© par Google Gemini AI
- **Prompts culturellement adaptÃ©s** : diffÃ©rents styles par langue
- **Suggestions temps rÃ©el** pendant la prÃ©sentation
- **Analyse contextuelle** basÃ©e sur le type de session et la langue
- **Conseils actionnables** avec encouragement adaptatif culturel
- **Fonctionnement** : pipeline AURA qui agrÃ¨ge des mÃ©triques vocales cÃ´tÃ© serveur, structure des prompts et appelle le service LLM ([`GeminiService`](backend/services/gemini_service.py:1)) pour produire des feedbacks (realtime_suggestion, coaching_result, performance_update).

### ğŸ“Š **Analytics et MÃ©triques Multilingues**
- **MÃ©triques spÃ©cifiques par langue** : benchmarks culturels et comparaisons
- **Scoring adaptatif** : Ã©valuation selon les attentes linguistiques
- **Suivi de progression** avec tendances temporelles par langue
- **DÃ©tection de jalons** d'amÃ©lioration culturellement pertinents
- **Rapports dÃ©taillÃ©s** avec insights linguistiques

### âš¡ **Communication Temps RÃ©el**
- **WebSocket streaming** pour feedback instantanÃ©
- **Pipeline de traitement** modulaire et extensible
- **Commandes de contrÃ´le** : start/stop, pause, configuration
- **Notifications de performance** et alertes live localisÃ©es

## ğŸ—ï¸ Architecture du SystÃ¨me

```mermaid
graph TB
    subgraph "Client Layer"
        A[React Frontend]
        C[Audio Input]
        U[/Page /tts-test/]
    end
    
    subgraph "API Gateway"
        D[FastAPI Server]
        E[WebSocket Handler]
        F[Authentication]
        R[/REST API/]
    end
    
    subgraph "Core Services"
        G[Audio Service]
        H[Storage Service]
        I[Gemini AI Service]
        V[Voice/TTS Service]
    end
    
    subgraph "Processing Pipeline"
        J[Analysis Processor]
        K[Feedback Processor]
        L[Metrics Processor]
        M[AURA Pipeline]
    end
    
    subgraph "Data Layer"
        N[PostgreSQL]
        O[Session Storage]
        P[Audio Buffer]
    end
    
    A --> D
    U --> R
    C --> E
    D --> F
    R --> V
    E --> G
    F --> H
    G --> J
    J --> K
    K --> L
    J --> M
    K --> M
    L --> M
    M --> I
    H --> N
    G --> P
    I --> O
    V --> R
```

### ğŸ”Š Sous-systÃ¨me TTS (HTTP vs WebSocket)

```mermaid
flowchart LR
    subgraph Frontend
      UI[/Page /tts-test/]
      MSE[MediaSource MP3]
    end

    subgraph Backend
      %% Utiliser des formes compatibles GitHub Mermaid:
      %% - Losange de dÃ©cision: {...} peut provoquer des erreurs â†’ utiliser ((...)) ou [text]
      %% - Sous-routine {{...}} n'est pas toujours supportÃ©e â†’ utiliser [...]
      REST[POST /api/v1/tts-stream]
      WS((WS /ws/tts))
      ProxyHTTP[Proxy ElevenLabs HTTP]
      ProxyWS[Proxy ElevenLabs WS]
    end

    subgraph ElevenLabs
      %% Remplacer les accolades par parenthÃ¨ses pour Ã©viter DIAMOND_START
      ELHTTP[[POST /v1/text-to-speech/(voice_id)/stream]]
      ELWS[[wss://.../stream-input]]
    end

    UI -- HTTP --> REST --> ProxyHTTP --> ELHTTP
    ELHTTP --> ProxyHTTP --> REST --> UI
    UI -. WS .-> WS --> ProxyWS --> ELWS
    ELWS --> ProxyWS --> WS -. BINARY/visÃ¨mes .-> UI
    UI --> MSE
```

## ğŸ”„ Pipeline de Traitement Audio et IA

```mermaid
sequenceDiagram
    participant C as Client
    participant WS as WebSocket
    participant REST as REST API
    participant AP as AURA Pipeline
    participant AS as Audio Service
    participant FP as Feedback Processor
    participant AI as Gemini AI
    
    C->>WS: Audio Chunk (100ms)
    WS->>AP: ProcessorPart(JSON)
    AP->>AS: Audio Analysis
    AS-->>AP: Voice Metrics
    AP->>FP: Analysis Results + Context
    FP->>AI: Prompt structurÃ© (langue, style, mÃ©triques)
    AI-->>FP: Suggestions IA (FR/EN)
    FP-->>AP: Coaching Data (realtime_suggestion, coaching_result)
    AP->>WS: Real-time Results
    WS->>C: Live Feedback

    Note over AP: Throttling/parallelisme configurable
    Note over AI: Prompts culturels FR/EN
```

## ğŸš€ Installation et Configuration

### PrÃ©requis
- Python 3.11+
- PostgreSQL 15+
- Google Cloud Account (pour Gemini AI)
- Compte ElevenLabs (clÃ© HTTP â€œxi-api-keyâ€; clÃ© WS optionnelle si vous activez le stream-input)

### 1. Cloner le Projet
```bash
git clone https://github.com/valak74200/AURA.git
cd AURA
```

### 2. Environnement Virtuel
```bash
python -m venv venv311
source venv311/bin/activate  # Linux/Mac
# ou
venv311\Scripts\activate     # Windows
```

### 3. Installation des DÃ©pendances
```bash
pip install -r requirements.txt
```

### 4. Configuration Environnement
CrÃ©er un fichier `.env` (backend/.env recommandÃ©) :

```bash
# API Keys
GEMINI_API_KEY=votre_clÃ©_gemini_ici
GOOGLE_CLOUD_PROJECT=votre_projet_gcp
# ElevenLabs
ELEVENLABS_API_KEY=votre_cle  # xi-api-key (HTTP). Pour WS stream-input: une clÃ© Bearer est requise cÃ´tÃ© amont.
ELEVENLABS_DEFAULT_VOICE_ID=21m00Tcm4TlvDq8ikWAM
ELEVENLABS_MODEL=eleven_multilingual_v2

# Base de DonnÃ©es
DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/aura_db

# Configuration Serveur
DEBUG=false
LOG_LEVEL=INFO
SECRET_KEY=votre_clÃ©_secrÃ¨te_32_caractÃ¨res_minimum

# Audio Processing
MAX_AUDIO_FILE_SIZE=10485760  # 10MB
AUDIO_SAMPLE_RATE=16000
AUDIO_CHUNK_SIZE=1600         # 100ms Ã  16kHz

# ModÃ¨les IA
DEFAULT_GEMINI_MODEL=gemini-2.5-flash
GEMINI_PRO_MODEL=gemini-2.5-pro
```

### 5. Base de DonnÃ©es
```bash
# CrÃ©er la base de donnÃ©es
python setup_database.py

# DÃ©marrer le serveur
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## ğŸ“¡ API Endpoints

### ğŸ” Authentication
```http
POST /api/v1/auth/register    # Inscription utilisateur
POST /api/v1/auth/login       # Connexion
GET  /api/v1/user/profile     # Profil utilisateur
```

### ğŸ­ Session Management
```http
POST   /api/v1/sessions                    # CrÃ©er session
GET    /api/v1/sessions/{id}              # RÃ©cupÃ©rer session
PUT    /api/v1/sessions/{id}              # Mettre Ã  jour
DELETE /api/v1/sessions/{id}              # Supprimer
GET    /api/v1/sessions?user_id=...       # Lister avec filtres
```

### ğŸ¤ Audio Processing
```http
POST /api/v1/sessions/{id}/audio/upload   # Upload fichier audio
POST /api/v1/sessions/{id}/audio/analyze  # Analyse chunk temps rÃ©el
```

### ğŸ’¬ Feedback & Analytics
```http
GET  /api/v1/sessions/{id}/feedback           # RÃ©cupÃ©rer feedback
POST /api/v1/sessions/{id}/feedback/generate  # GÃ©nÃ©rer feedback custom
GET  /api/v1/sessions/{id}/analytics          # Analytics dÃ©taillÃ©es
```

### ğŸ”§ System
```http
GET /api/v1/health    # Health check
GET /api/v1/test      # Tests d'intÃ©gration
```

### ğŸŒ Multilingual APIs
```http
# Sessions avec support linguistique
POST /api/v1/sessions
{
  "config": {
    "language": "fr|en",        # Langue de la session
    "session_type": "practice"
  }
}

# Analyse audio avec adaptation linguistique
POST /api/v1/sessions/{id}/audio/upload
# â†’ Analyse automatiquement adaptÃ©e Ã  la langue de session

# Feedback culturellement adaptÃ©
POST /api/v1/sessions/{id}/feedback/generate
# â†’ Prompts et style adaptÃ©s Ã  la langue
```

### âš¡ WebSocket Endpoints
```http
WS /ws/session/{session_id}    # Connexion temps rÃ©el
WS /ws/test                    # Endpoint de test
```

## ğŸ”Š TTS (SynthÃ¨se Vocale) ElevenLabs

Deux modes sont supportÃ©s:
- HTTP streaming (fonctionnel par dÃ©faut)
- WebSocket â€œstream-inputâ€ (temps rÃ©el, nÃ©cessite une clÃ© spÃ©cifique cÃ´tÃ© ElevenLabs)

### Endpoints backend
- HTTP proxy: `POST /api/v1/tts-stream` â†’ proxy vers `POST /v1/text-to-speech/{voice_id}/stream`
- WebSocket proxy: `WS /ws/tts` â†’ proxy vers `wss://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream-input`

### Authentification ElevenLabs
- HTTP: header amont `xi-api-key: <votre_cle_http>`
- WebSocket: header amont `Authorization: Bearer <votre_cle_ws>`
  - Si vous ne disposez que dâ€™une clÃ© â€œxi-api-keyâ€, utilisez le mode HTTP (lâ€™UI /tts-test est prÃ©vue pour fonctionner en HTTP par dÃ©faut).
  - En cas dâ€™absence de clÃ© WS, le WS renverra typiquement `invalid_authorization_header (code 1008)`.

### UI de test
- Page: `/tts-test` (frontend)
- Panneaux: Logs WS (client), Meta, Erreurs, VisÃ¨mes
- Lecture: MediaSource MP3 cÃ´tÃ© navigateur en mode HTTP

### ParamÃ¨tres utiles
- Voice ID par dÃ©faut: `21m00Tcm4TlvDq8ikWAM` (Rachel). Utilisez des IDs de voix (pas des noms).
- ModÃ¨le par dÃ©faut: `eleven_multilingual_v2`
- Format: `mp3_44100_128`

## ğŸ”Œ Utilisation WebSocket

### Connexion et Messages
```javascript
// Connexion
const ws = new WebSocket('ws://localhost:8000/ws/session/123')

// Envoyer chunk audio
ws.send(JSON.stringify({
  type: 'audio_chunk',
  audio_data: base64AudioData,
  sample_rate: 16000,
  timestamp: Date.now()
}))

// Messages reÃ§us
ws.onmessage = (event) => {
  const data = JSON.parse(event.data)
  switch(data.type) {
    case 'coaching_result':
      // RÃ©sultats d'analyse complÃ¨te
      break
    case 'realtime_feedback':
      // Suggestions instantanÃ©es
      break
    case 'milestone_achieved':
      // Jalons atteints
      break
  }
}
```

## ğŸ§ª Tests

### ExÃ©cuter tous les Tests
```bash
# Tests complets
pytest tests/ -v

# Tests spÃ©cifiques
pytest tests/test_api/test_sessions.py -v
pytest tests/test_services/ -v

# Avec couverture
pytest tests/ --cov=app --cov-report=html
```

### Structure des Tests
```
tests/
â”œâ”€â”€ conftest.py                    # Configuration pytest
â”œâ”€â”€ test_api/
â”‚   â”œâ”€â”€ test_auth.py              # Tests authentification
â”‚   â”œâ”€â”€ test_sessions.py          # Tests sessions (24 tests)
â”‚   â””â”€â”€ test_websocket.py         # Tests WebSocket
â”œâ”€â”€ test_services/
â”‚   â””â”€â”€ test_auth_service.py      # Tests services
â”œâ”€â”€ test_processors/              # Tests pipeline
â”œâ”€â”€ test_multilingual.py          # Tests intÃ©gration multilingue (15 tests)
â””â”€â”€ test_multilingual_metrics.py  # Tests mÃ©triques multilingues (17 tests)
```

### Tests Multilingues
```bash
# Tests complets multilingues
pytest tests/test_multilingual.py -v
pytest tests/test_multilingual_metrics.py -v

# Tests par fonctionnalitÃ©
pytest tests/test_multilingual.py::TestLanguageConfiguration -v
pytest tests/test_multilingual.py::TestMultilingualAudioAnalysis -v
pytest tests/test_multilingual.py::TestGeminiMultilingual -v
```

## ğŸ“Š ModÃ¨les de DonnÃ©es

### Session Multilingue
```python
{
  "id": "uuid",
  "user_id": "string",
  "title": "string", 
  "session_type": "practice|presentation|training",
  "language": "fr|en",           # Langue de la session
  "status": "active|completed|paused",
  "config": {
    "language": "fr|en",         # Configuration linguistique
    "max_duration": 1800,
    "feedback_frequency": 5,
    "real_time_feedback": true,
    "ai_coaching": true
  },
  "created_at": "datetime",
  "started_at": "datetime",
  "ended_at": "datetime"
}
```

### Feedback IA Multilingue
```python
{
  "session_id": "uuid",
  "language": "fr|en",          # Langue du feedback
  "feedback_items": [
    {
      "type": "volume|pace|clarity|cultural_adaptation",
      "category": "technique|delivery|content|cultural",
      "severity": "info|warning|critical",
      "message": "Votre volume est appropriÃ©", # LocalisÃ©
      "score": 0.8,
      "suggestions": ["Continuez ainsi"],     # Culturellement adaptÃ©
      "cultural_context": "french_formality|english_engagement"
    }
  ],
  "cultural_adaptation_score": 0.85,  # Score d'adaptation culturelle
  "generated_at": "datetime"
}
```

### MÃ©triques Multilingues
```python
{
  "language": "fr|en",
  "core_metrics": {
    "pace": {
      "wpm": 180,
      "optimal_wpm": 282,      # DiffÃ©rent par langue (fr: 282, en: 222)
      "score": 0.85,
      "feedback": "Rythme adaptÃ© au franÃ§ais"
    },
    "volume": {
      "level": 0.06,
      "target_level": 0.06,    # OptimisÃ© par langue
      "score": 0.9
    },
    "clarity": {
      "raw_score": 0.85,
      "adjusted_score": 0.88,  # PondÃ©rÃ© par langue
      "weight_applied": 1.2
    }
  },
  "cultural_metrics": {
    "cultural_adaptation_score": 0.82,
    "cultural_factors": {
      "formality_level": 0.85,      # Important en franÃ§ais
      "engagement_style": 0.78,     # Important en anglais
      "directness_level": 0.60,
      "emotional_expression": 0.75
    }
  },
  "benchmark_comparison": {
    "overall_percentile": 75,        # ComparÃ© aux locuteurs de cette langue
    "strengths": ["pace", "clarity"],
    "improvement_areas": ["pitch_variation"]
  },
  "language_insights": [
    {
      "type": "cultural",
      "level": "excellent",
      "title": "MaÃ®trise du Style FranÃ§ais",
      "message": "Vous maÃ®trisez les codes de prÃ©sentation franÃ§ais",
      "action": "Continuez Ã  cultiver cette Ã©lÃ©gance"
    }
  ]
}
```

## ğŸ”§ Configuration AvancÃ©e

### Pipeline de Traitement
```python
# ConfigurÃ© dans AuraPipeline
pipeline_config = {
    "enable_parallel_processing": True,
    "chunk_timeout_seconds": 5.0,
    "error_retry_count": 2,
    "feedback_throttling": True,
    "metrics_calculation_interval": 3,
    "quality_threshold": 0.5
}
```

### ModÃ¨les Gemini
```python
# Configuration IA
DEFAULT_GEMINI_MODEL = "gemini-2.5-flash"      # Rapide
GEMINI_PRO_MODEL = "gemini-2.5-pro"            # QualitÃ© max
DEFAULT_THINKING_BUDGET = 1000                  # Tokens
```

## ğŸš€ DÃ©ploiement

### Docker (RecommandÃ©)
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY backend/requirements.txt ./requirements.txt
RUN pip install -r requirements.txt

COPY backend ./backend
WORKDIR /app/backend
EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Production
```bash
# Avec Gunicorn (depuis /backend)
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8000

# Variables d'environnement production
export ENVIRONMENT=production
export DEBUG=false
export LOG_LEVEL=WARNING
```

## ğŸ“ˆ Monitoring et Performance

### MÃ©triques Disponibles
- **Temps de traitement** par chunk audio
- **Taux de succÃ¨s** du pipeline
- **Utilisation des services** (Storage, Audio, Gemini)
- **Erreurs et exceptions** avec traces complÃ¨tes
- **Sessions actives** et statistiques d'usage

### Logs StructurÃ©s
```python
# Format JSON avec mÃ©tadonnÃ©es complÃ¨tes
{
  "timestamp": "2024-01-01T12:00:00Z",
  "level": "INFO",
  "logger": "aura.processors.pipeline",
  "message": "Pipeline processing completed",
  "session_id": "uuid",
  "chunk_number": 42,
  "processing_time_ms": 150.5
}
```

## ğŸ¤ Contribution

### Structure du Code
```
app/
â”œâ”€â”€ api/                 # Endpoints FastAPI
â”œâ”€â”€ config.py           # Configuration
â”œâ”€â”€ database.py         # Connexion DB
â””â”€â”€ main.py             # Application principale

models/                 # ModÃ¨les Pydantic
â”œâ”€â”€ session.py
â”œâ”€â”€ feedback.py
â”œâ”€â”€ analytics.py
â””â”€â”€ user.py

processors/             # Pipeline de traitement
â”œâ”€â”€ aura_pipeline.py    # Pipeline principal
â”œâ”€â”€ analysis_processor.py
â”œâ”€â”€ feedback_processor.py
â””â”€â”€ metrics_processor.py

services/               # Services mÃ©tier
â”œâ”€â”€ audio_service.py
â”œâ”€â”€ storage_service.py
â”œâ”€â”€ gemini_service.py
â””â”€â”€ auth_service.py

utils/                  # Utilitaires
â”œâ”€â”€ logging.py
â”œâ”€â”€ exceptions.py
â””â”€â”€ audio_utils.py
```

### Standards de Code
- **Type hints** obligatoires
- **Docstrings** pour toutes les fonctions publiques
- **Tests** pour chaque nouvelle fonctionnalitÃ©
- **Logging** structurÃ© avec contexte
- **Gestion d'erreurs** avec exceptions custom

## ğŸ“ Roadmap

### âœ… ComplÃ©tÃ©
- [x] Architecture FastAPI complÃ¨te
- [x] Pipeline audio temps rÃ©el
- [x] IntÃ©gration Gemini AI
- [x] WebSocket streaming
- [x] Tests complets (88 tests passants)
- [x] Analytics avancÃ©es
- [x] Documentation API

### ğŸ”„ En Cours
- [ ] Interface React + Vite.js (frontend/)
- [ ] Capture microphone temps rÃ©el (frontend/components/audio)
- [ ] Dashboard analytics visuel
- [ ] HTTP TTS par dÃ©faut (WS activÃ© quand clÃ© Bearer est disponible)
- [ ] ObservabilitÃ© /api/v1/tts-stream (octets, durÃ©e, statut amont)
- [ ] AmÃ©liorations pipeline IA (prompts et coÃ»ts)
- [ ] Mobile app

### ğŸš€ Futur
- [ ] Support multi-langues (EN, ES)
- [ ] IntÃ©gration vidÃ©o
- [ ] Analytics prÃ©dictives
- [ ] API publique avec rate limiting
- [ ] DÃ©ploiement cloud (AWS/GCP)

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ†˜ Support

- **Documentation API** : http://localhost:8000/docs (Swagger)
- **Issues** : [GitHub Issues](https://github.com/valak74200/AURA/issues)

---

<div align="center">
  <strong>ğŸ¯ AURA - Transformez vos prÃ©sentations avec l'IA</strong><br/>
  DÃ©veloppÃ© avec â¤ï¸ pour l'excellence oratoire
</div>
