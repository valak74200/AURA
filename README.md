# üéØ AURA - Assistant de Coaching de Pr√©sentation Aliment√© par l'IA

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue.svg)](https://postgresql.org)
[![Gemini AI](https://img.shields.io/badge/Gemini-AI-orange.svg)](https://ai.google.dev)
[![ElevenLabs TTS](https://img.shields.io/badge/ElevenLabs-TTS-purple.svg)](https://api.elevenlabs.io)
[![WebSocket](https://img.shields.io/badge/WebSocket-Real--time-red.svg)](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API)

**AURA** est une plateforme avanc√©e de coaching vocal et de pr√©sentation qui combine l'intelligence artificielle moderne avec des techniques d'analyse audio en temps r√©el pour offrir une exp√©rience de formation personnalis√©e et efficace.

## üåü Fonctionnalit√©s Principales

### üåç **Support Multilingue Avanc√©**
- **Langues support√©es** : Fran√ßais et Anglais avec adaptation culturelle compl√®te
- **Analyse audio adaptative** : seuils et m√©triques optimis√©s par langue
- **Coaching culturel** : style fran√ßais (structure/√©l√©gance) vs anglais (engagement/storytelling)
- **Benchmarks sp√©cifiques** : comparaisons de performance par langue
- **Interface localis√©e** : messages et feedback dans la langue de session

### üé§ **Analyse Audio Avanc√©e**
- **Traitement temps r√©el** de chunks audio (100ms √† 16kHz)
- **M√©triques vocales compl√®tes** : volume, clart√©, rythme, tonalit√©, pauses
- **Support multi-format** : WAV, MP3, M4A, OGG (jusqu'√† 10MB)
- **D√©tection d'activit√© vocale** et analyse de qualit√© automatique
- **Adaptation linguistique** : param√®tres d'analyse optimis√©s par langue

### ü§ñ **IA de Coaching Intelligente**
- **Feedback personnalis√©** g√©n√©r√© par Google Gemini AI
- **Prompts culturellement adapt√©s** : diff√©rents styles par langue
- **Suggestions temps r√©el** pendant la pr√©sentation
- **Analyse contextuelle** bas√©e sur le type de session et la langue
- **Conseils actionnables** avec encouragement adaptatif culturel
- **Fonctionnement** : pipeline AURA qui agr√®ge des m√©triques vocales c√¥t√© serveur, structure des prompts et appelle le service LLM ([`GeminiService`](backend/services/gemini_service.py:1)) pour produire des feedbacks (realtime_suggestion, coaching_result, performance_update).

### üìä **Analytics et M√©triques Multilingues**
- **M√©triques sp√©cifiques par langue** : benchmarks culturels et comparaisons
- **Scoring adaptatif** : √©valuation selon les attentes linguistiques
- **Suivi de progression** avec tendances temporelles par langue
- **D√©tection de jalons** d'am√©lioration culturellement pertinents
- **Rapports d√©taill√©s** avec insights linguistiques

### ‚ö° **Communication Temps R√©el**
- **WebSocket streaming** pour feedback instantan√©
- **Pipeline de traitement** modulaire et extensible
- **Commandes de contr√¥le** : start/stop, pause, configuration
- **Notifications de performance** et alertes live localis√©es

## üèóÔ∏è Architecture du Syst√®me

```mermaid
graph TB
    subgraph "Client Layer"
        A[React Frontend]
        C[Audio Input]
        U[/Page /tts-test/]
    end
    
    subgraph "API Gateway"
        D[FastAPI Server]
        E[WebSocket Handler]
        F[Authentication]
        R[/REST API/]
    end
    
    subgraph "Core Services"
        G[Audio Service]
        H[Storage Service]
        I[Gemini AI Service]
        V[Voice/TTS Service]
    end
    
    subgraph "Processing Pipeline"
        J[Analysis Processor]
        K[Feedback Processor]
        L[Metrics Processor]
        M[AURA Pipeline]
    end
    
    subgraph "Data Layer"
        N[PostgreSQL]
        O[Session Storage]
        P[Audio Buffer]
    end
    
    A --> D
    U --> R
    C --> E
    D --> F
    R --> V
    E --> G
    F --> H
    G --> J
    J --> K
    K --> L
    J --> M
    K --> M
    L --> M
    M --> I
    H --> N
    G --> P
    I --> O
    V --> R
```

### üîä Sous-syst√®me TTS (HTTP vs WebSocket)

```mermaid
flowchart LR
    subgraph Frontend
      UI[/Page /tts-test/]
      MSE[MediaSource MP3]
    end

    subgraph Backend
      %% Utiliser des formes compatibles GitHub Mermaid:
      %% - Losange de d√©cision: {...} peut provoquer des erreurs ‚Üí utiliser ((...)) ou [text]
      %% - Sous-routine {{...}} n'est pas toujours support√©e ‚Üí utiliser [...]
      REST[POST /api/v1/tts-stream]
      WS((WS /ws/tts))
      ProxyHTTP[Proxy ElevenLabs HTTP]
      ProxyWS[Proxy ElevenLabs WS]
    end

    subgraph ElevenLabs
      %% Remplacer les accolades par parenth√®ses pour √©viter DIAMOND_START
      ELHTTP[[POST /v1/text-to-speech/(voice_id)/stream]]
      ELWS[[wss://.../stream-input]]
    end

    UI -- HTTP --> REST --> ProxyHTTP --> ELHTTP
    ELHTTP --> ProxyHTTP --> REST --> UI
    UI -. WS .-> WS --> ProxyWS --> ELWS
    ELWS --> ProxyWS --> WS -. BINARY/vis√®mes .-> UI
    UI --> MSE
```

## üîÑ Pipeline de Traitement Audio et IA

```mermaid
sequenceDiagram
    participant C as Client
    participant WS as WebSocket
    participant REST as REST API
    participant AP as AURA Pipeline
    participant AS as Audio Service
    participant FP as Feedback Processor
    participant AI as Gemini AI
    
    C->>WS: Audio Chunk (100ms)
    WS->>AP: ProcessorPart(JSON)
    AP->>AS: Audio Analysis
    AS-->>AP: Voice Metrics
    AP->>FP: Analysis Results + Context
    FP->>AI: Prompt structur√© (langue, style, m√©triques)
    AI-->>FP: Suggestions IA (FR/EN)
    FP-->>AP: Coaching Data (realtime_suggestion, coaching_result)
    AP->>WS: Real-time Results
    WS->>C: Live Feedback

    Note over AP: Throttling/parallelisme configurable
    Note over AI: Prompts culturels FR/EN
```

## üöÄ Installation et Configuration

### Pr√©requis
- Python 3.11+
- PostgreSQL 15+
- Google Cloud Account (pour Gemini AI)
- Compte ElevenLabs (cl√© HTTP ‚Äúxi-api-key‚Äù; cl√© WS optionnelle si vous activez le stream-input)

### 1. Cloner le Projet
```bash
git clone https://github.com/valak74200/AURA.git
cd AURA
```

### 2. Environnement Virtuel
```bash
python -m venv venv311
source venv311/bin/activate  # Linux/Mac
# ou
venv311\Scripts\activate     # Windows
```

### 3. Installation des D√©pendances
```bash
pip install -r requirements.txt
```

### 4. Configuration Environnement
Cr√©er un fichier `.env` (backend/.env recommand√©) :

```bash
# API Keys
GEMINI_API_KEY=votre_cl√©_gemini_ici
GOOGLE_CLOUD_PROJECT=votre_projet_gcp
# ElevenLabs
ELEVENLABS_API_KEY=votre_cle  # xi-api-key (HTTP). Pour WS stream-input: une cl√© Bearer est requise c√¥t√© amont.
ELEVENLABS_DEFAULT_VOICE_ID=21m00Tcm4TlvDq8ikWAM
ELEVENLABS_MODEL=eleven_multilingual_v2

# Base de Donn√©es
DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/aura_db

# Configuration Serveur
DEBUG=false
LOG_LEVEL=INFO
SECRET_KEY=votre_cl√©_secr√®te_32_caract√®res_minimum

# Audio Processing
MAX_AUDIO_FILE_SIZE=10485760  # 10MB
AUDIO_SAMPLE_RATE=16000
AUDIO_CHUNK_SIZE=1600         # 100ms √† 16kHz

# Mod√®les IA
DEFAULT_GEMINI_MODEL=gemini-2.5-flash
GEMINI_PRO_MODEL=gemini-2.5-pro
```

### 5. Base de Donn√©es
```bash
# Cr√©er la base de donn√©es
python setup_database.py

# D√©marrer le serveur
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## üì° API Endpoints

### üîê Authentication
```http
POST /api/v1/auth/register    # Inscription utilisateur
POST /api/v1/auth/login       # Connexion
GET  /api/v1/user/profile     # Profil utilisateur
```

### üé≠ Session Management
```http
POST   /api/v1/sessions                    # Cr√©er session
GET    /api/v1/sessions/{id}              # R√©cup√©rer session
PUT    /api/v1/sessions/{id}              # Mettre √† jour
DELETE /api/v1/sessions/{id}              # Supprimer
GET    /api/v1/sessions?user_id=...       # Lister avec filtres
```

### üé§ Audio Processing
```http
POST /api/v1/sessions/{id}/audio/upload   # Upload fichier audio
POST /api/v1/sessions/{id}/audio/analyze  # Analyse chunk temps r√©el
```

### üí¨ Feedback & Analytics
```http
GET  /api/v1/sessions/{id}/feedback           # R√©cup√©rer feedback
POST /api/v1/sessions/{id}/feedback/generate  # G√©n√©rer feedback custom
GET  /api/v1/sessions/{id}/analytics          # Analytics d√©taill√©es
```

### üîß System
```http
GET /api/v1/health    # Health check
GET /api/v1/test      # Tests d'int√©gration
```

### üåç Multilingual APIs
```http
# Sessions avec support linguistique
POST /api/v1/sessions
{
  "config": {
    "language": "fr|en",        # Langue de la session
    "session_type": "practice"
  }
}

# Analyse audio avec adaptation linguistique
POST /api/v1/sessions/{id}/audio/upload
# ‚Üí Analyse automatiquement adapt√©e √† la langue de session

# Feedback culturellement adapt√©
POST /api/v1/sessions/{id}/feedback/generate
# ‚Üí Prompts et style adapt√©s √† la langue
```

### ‚ö° WebSocket Endpoints
```http
WS /ws/session/{session_id}    # Connexion temps r√©el
WS /ws/test                    # Endpoint de test
```

## üîä TTS (Synth√®se Vocale) ElevenLabs

Deux modes sont support√©s:
- HTTP streaming (fonctionnel par d√©faut)
- WebSocket ‚Äústream-input‚Äù (temps r√©el, n√©cessite une cl√© sp√©cifique c√¥t√© ElevenLabs)

### Endpoints backend
- HTTP proxy: `POST /api/v1/tts-stream` ‚Üí proxy vers `POST /v1/text-to-speech/{voice_id}/stream`
- WebSocket proxy: `WS /ws/tts` ‚Üí proxy vers `wss://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream-input`

### Authentification ElevenLabs
- HTTP: header amont `xi-api-key: <votre_cle_http>`
- WebSocket: header amont `Authorization: Bearer <votre_cle_ws>`
  - Si vous ne disposez que d‚Äôune cl√© ‚Äúxi-api-key‚Äù, utilisez le mode HTTP (l‚ÄôUI /tts-test est pr√©vue pour fonctionner en HTTP par d√©faut).
  - En cas d‚Äôabsence de cl√© WS, le WS renverra typiquement `invalid_authorization_header (code 1008)`.

### UI de test
- Page: `/tts-test` (frontend)
- Panneaux: Logs WS (client), Meta, Erreurs, Vis√®mes
- Lecture: MediaSource MP3 c√¥t√© navigateur en mode HTTP

### Param√®tres utiles
- Voice ID par d√©faut: `21m00Tcm4TlvDq8ikWAM` (Rachel). Utilisez des IDs de voix (pas des noms).
- Mod√®le par d√©faut: `eleven_multilingual_v2`
- Format: `mp3_44100_128`

## üîå Utilisation WebSocket

### Connexion et Messages
```javascript
// Connexion
const ws = new WebSocket('ws://localhost:8000/ws/session/123')

// Envoyer chunk audio
ws.send(JSON.stringify({
  type: 'audio_chunk',
  audio_data: base64AudioData,
  sample_rate: 16000,
  timestamp: Date.now()
}))

// Messages re√ßus
ws.onmessage = (event) => {
  const data = JSON.parse(event.data)
  switch(data.type) {
    case 'coaching_result':
      // R√©sultats d'analyse compl√®te
      break
    case 'realtime_feedback':
      // Suggestions instantan√©es
      break
    case 'milestone_achieved':
      // Jalons atteints
      break
  }
}
```

## üß™ Tests

### Ex√©cuter tous les Tests
```bash
# Tests complets
pytest tests/ -v

# Tests sp√©cifiques
pytest tests/test_api/test_sessions.py -v
pytest tests/test_services/ -v

# Avec couverture
pytest tests/ --cov=app --cov-report=html
```

### Structure des Tests
```
tests/
‚îú‚îÄ‚îÄ conftest.py                    # Configuration pytest
‚îú‚îÄ‚îÄ test_api/
‚îÇ   ‚îú‚îÄ‚îÄ test_auth.py              # Tests authentification
‚îÇ   ‚îú‚îÄ‚îÄ test_sessions.py          # Tests sessions (24 tests)
‚îÇ   ‚îî‚îÄ‚îÄ test_websocket.py         # Tests WebSocket
‚îú‚îÄ‚îÄ test_services/
‚îÇ   ‚îî‚îÄ‚îÄ test_auth_service.py      # Tests services
‚îú‚îÄ‚îÄ test_processors/              # Tests pipeline
‚îú‚îÄ‚îÄ test_multilingual.py          # Tests int√©gration multilingue (15 tests)
‚îî‚îÄ‚îÄ test_multilingual_metrics.py  # Tests m√©triques multilingues (17 tests)
```

### Tests Multilingues
```bash
# Tests complets multilingues
pytest tests/test_multilingual.py -v
pytest tests/test_multilingual_metrics.py -v

# Tests par fonctionnalit√©
pytest tests/test_multilingual.py::TestLanguageConfiguration -v
pytest tests/test_multilingual.py::TestMultilingualAudioAnalysis -v
pytest tests/test_multilingual.py::TestGeminiMultilingual -v
```

## üìä Mod√®les de Donn√©es

### Session Multilingue
```python
{
  "id": "uuid",
  "user_id": "string",
  "title": "string", 
  "session_type": "practice|presentation|training",
  "language": "fr|en",           # Langue de la session
  "status": "active|completed|paused",
  "config": {
    "language": "fr|en",         # Configuration linguistique
    "max_duration": 1800,
    "feedback_frequency": 5,
    "real_time_feedback": true,
    "ai_coaching": true
  },
  "created_at": "datetime",
  "started_at": "datetime",
  "ended_at": "datetime"
}
```

### Feedback IA Multilingue
```python
{
  "session_id": "uuid",
  "language": "fr|en",          # Langue du feedback
  "feedback_items": [
    {
      "type": "volume|pace|clarity|cultural_adaptation",
      "category": "technique|delivery|content|cultural",
      "severity": "info|warning|critical",
      "message": "Votre volume est appropri√©", # Localis√©
      "score": 0.8,
      "suggestions": ["Continuez ainsi"],     # Culturellement adapt√©
      "cultural_context": "french_formality|english_engagement"
    }
  ],
  "cultural_adaptation_score": 0.85,  # Score d'adaptation culturelle
  "generated_at": "datetime"
}
```

### M√©triques Multilingues
```python
{
  "language": "fr|en",
  "core_metrics": {
    "pace": {
      "wpm": 180,
      "optimal_wpm": 282,      # Diff√©rent par langue (fr: 282, en: 222)
      "score": 0.85,
      "feedback": "Rythme adapt√© au fran√ßais"
    },
    "volume": {
      "level": 0.06,
      "target_level": 0.06,    # Optimis√© par langue
      "score": 0.9
    },
    "clarity": {
      "raw_score": 0.85,
      "adjusted_score": 0.88,  # Pond√©r√© par langue
      "weight_applied": 1.2
    }
  },
  "cultural_metrics": {
    "cultural_adaptation_score": 0.82,
    "cultural_factors": {
      "formality_level": 0.85,      # Important en fran√ßais
      "engagement_style": 0.78,     # Important en anglais
      "directness_level": 0.60,
      "emotional_expression": 0.75
    }
  },
  "benchmark_comparison": {
    "overall_percentile": 75,        # Compar√© aux locuteurs de cette langue
    "strengths": ["pace", "clarity"],
    "improvement_areas": ["pitch_variation"]
  },
  "language_insights": [
    {
      "type": "cultural",
      "level": "excellent",
      "title": "Ma√Ætrise du Style Fran√ßais",
      "message": "Vous ma√Ætrisez les codes de pr√©sentation fran√ßais",
      "action": "Continuez √† cultiver cette √©l√©gance"
    }
  ]
}
```

## üîß Configuration Avanc√©e

### Pipeline de Traitement
```python
# Configur√© dans AuraPipeline
pipeline_config = {
    "enable_parallel_processing": True,
    "chunk_timeout_seconds": 5.0,
    "error_retry_count": 2,
    "feedback_throttling": True,
    "metrics_calculation_interval": 3,
    "quality_threshold": 0.5
}
```

### Mod√®les Gemini
```python
# Configuration IA
DEFAULT_GEMINI_MODEL = "gemini-2.5-flash"      # Rapide
GEMINI_PRO_MODEL = "gemini-2.5-pro"            # Qualit√© max
DEFAULT_THINKING_BUDGET = 1000                  # Tokens
```

## üöÄ D√©ploiement

### Docker (Recommand√©)
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY backend/requirements.txt ./requirements.txt
RUN pip install -r requirements.txt

COPY backend ./backend
WORKDIR /app/backend
EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Production
```bash
# Avec Gunicorn (depuis /backend)
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8000

# Variables d'environnement production
export ENVIRONMENT=production
export DEBUG=false
export LOG_LEVEL=WARNING
```

## üìà Monitoring et Performance

### M√©triques Disponibles
- **Temps de traitement** par chunk audio
- **Taux de succ√®s** du pipeline
- **Utilisation des services** (Storage, Audio, Gemini)
- **Erreurs et exceptions** avec traces compl√®tes
- **Sessions actives** et statistiques d'usage

### Logs Structur√©s
```python
# Format JSON avec m√©tadonn√©es compl√®tes
{
  "timestamp": "2024-01-01T12:00:00Z",
  "level": "INFO",
  "logger": "aura.processors.pipeline",
  "message": "Pipeline processing completed",
  "session_id": "uuid",
  "chunk_number": 42,
  "processing_time_ms": 150.5
}
```

## ü§ù Contribution

### Structure du Code
```
app/
‚îú‚îÄ‚îÄ api/                 # Endpoints FastAPI
‚îú‚îÄ‚îÄ config.py           # Configuration
‚îú‚îÄ‚îÄ database.py         # Connexion DB
‚îî‚îÄ‚îÄ main.py             # Application principale

models/                 # Mod√®les Pydantic
‚îú‚îÄ‚îÄ session.py
‚îú‚îÄ‚îÄ feedback.py
‚îú‚îÄ‚îÄ analytics.py
‚îî‚îÄ‚îÄ user.py

processors/             # Pipeline de traitement
‚îú‚îÄ‚îÄ aura_pipeline.py    # Pipeline principal
‚îú‚îÄ‚îÄ analysis_processor.py
‚îú‚îÄ‚îÄ feedback_processor.py
‚îî‚îÄ‚îÄ metrics_processor.py

services/               # Services m√©tier
‚îú‚îÄ‚îÄ audio_service.py
‚îú‚îÄ‚îÄ storage_service.py
‚îú‚îÄ‚îÄ gemini_service.py
‚îî‚îÄ‚îÄ auth_service.py

utils/                  # Utilitaires
‚îú‚îÄ‚îÄ logging.py
‚îú‚îÄ‚îÄ exceptions.py
‚îî‚îÄ‚îÄ audio_utils.py
```

### Standards de Code
- **Type hints** obligatoires
- **Docstrings** pour toutes les fonctions publiques
- **Tests** pour chaque nouvelle fonctionnalit√©
- **Logging** structur√© avec contexte
- **Gestion d'erreurs** avec exceptions custom

## üìù Roadmap

### ‚úÖ Compl√©t√©
- [x] Architecture FastAPI compl√®te
- [x] Pipeline audio temps r√©el
- [x] Int√©gration Gemini AI
- [x] WebSocket streaming
- [x] Tests complets (88 tests passants)
- [x] Analytics avanc√©es
- [x] Documentation API

### üîÑ En Cours
- [ ] Interface React + Vite.js (frontend/)
- [ ] Capture microphone temps r√©el (frontend/components/audio)
- [ ] Dashboard analytics visuel
- [ ] HTTP TTS par d√©faut (WS activ√© quand cl√© Bearer est disponible)
- [ ] Observabilit√© /api/v1/tts-stream (octets, dur√©e, statut amont)
- [ ] Am√©liorations pipeline IA (prompts et co√ªts)
- [ ] Mobile app

### üöÄ Futur
- [ ] Support multi-langues (EN, ES)
- [ ] Int√©gration vid√©o
- [ ] Analytics pr√©dictives
- [ ] API publique avec rate limiting
- [ ] D√©ploiement cloud (AWS/GCP)

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

## üÜò Support

- **Documentation API** : http://localhost:8000/docs (Swagger)
- **Issues** : [GitHub Issues](https://github.com/valak74200/AURA/issues)

---

<div align="center">
  <strong>üéØ AURA - Transformez vos pr√©sentations avec l'IA</strong><br/>
  D√©velopp√© avec ‚ù§Ô∏è pour l'excellence oratoire
</div>
